---
title: "HMW 1- Data 621"
author: "OMER OZEREN"
output:
  word_document:
    toc: yes
    toc_depth: '5'
  html_document:
    highlight: tango
    theme: journal
    toc: yes
    toc_depth: 5
    toc_float: yes
always_allow_html: yes    
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, comment=NA, message=FALSE, warning=FALSE)
library(tidyverse)
library(kableExtra)
library(corrplot)
library(caret)
library(DMwR)
library(knitr)
library(ggplot2)
library(gridExtra)
library(dplyr)
library(Hmisc)
```

## Introduction

```{r read_data, echo=FALSE}
# Read in the training data
training <- read.csv("https://raw.githubusercontent.com/omerozeren/DATA621/master/moneyball-training-data.csv") 
# Read in the evaluation data
evaluation <- read.csv("https://raw.githubusercontent.com/omerozeren/DATA621/master/moneyball-evaluation-data.csv")
```

I have been given a dataset with `r nrow(training)` records summarizing a major league baseball team's season.  All statistics have been adjusted to match the performance of a 162 game season.  The objective is to build a linear regression model to predict the number of wins for a team.
This report covers an attempt to build a model to predict number of wins of a baseball team in a season based on several offensive and deffensive statistics. Resulting model explained about 36% of variability in the target variable and included most of the provided explanatory variables. Some potentially  variables were not included in the data set due to missing values.I used KNN for variable missing values imputtion.

## DATA EXPLORATION

Each record in the data set represents the performance of the team for the given year adjusted to the current length of the season - 162 games. The data set includes 16 variables and the training set includes 2,276 records.

```{r Data Frame Structure}
sumtable = data.frame(Variable = character(),
                   Min = integer(),
                   Median = integer(),
                   Mean = double(),
                   SD = double(),
                   Max = integer(),
                   Num_NaN = integer())
for (i in 2:17) {
  sumtable <- rbind(sumtable, data.frame(Variable = colnames(training)[i],
                                   Min = min(training[,i], na.rm=TRUE),
                                   Median = median(training[,i], na.rm=TRUE),
                                   Mean = mean(training[,i], na.rm=TRUE),
                                   SD = sd(training[,i], na.rm=TRUE),
                                   Max = max(training[,i], na.rm=TRUE),
                                   Num_NaN = sum(is.na(training[,i])))
                 )
}
colnames(sumtable) <- c("", "Min", "Median", "Mean", "SD", "Max", "Num of NaN")
sumtable
```




```{r small_multiples_density, warning=FALSE}
training %>%
  gather(variable, value, TARGET_WINS:TEAM_FIELDING_DP) %>%
  ggplot(., aes(value)) + 
  geom_density(fill = "indianred4", color="indianred4") + 
  facet_wrap(~variable, scales ="free", ncol = 4) +
  labs(x = element_blank(), y = element_blank())
```

```{r}
quick_summary <- function(df){
  df %>%
    summary() %>%
    kable() %>%
    kable_styling()
}
quick_summary(training)
```

Some initial observations:  

* The response variable (`TARGET_WINS`) looks to be normally distributed.  This supports the working theory that there are good teams and bad teams.  There are also a lot of average teams.
* There are also quite a few variables with missing values.  We may need to deal with these in order to have the largest data set possible for modeling.
* A couple variables are bimodal (`TEAM_BATTING_HR`, `TEAM_BATTING_SO` `TEAM_PITCHING_HR`).  This may be a challenge as some of them are missing values and that may be a challenge in filling in missing values.
* Some variables are right skewed (`TEAM_BASERUN_CS`, `TEAM_BASERUN_SB`, etc.).  This might support the good team theory.  It may also introduce non-normally distributed residuals in the model.  We shall see.  

#### Zero Values

There are also variables that have verly low values.  Let's see how big of a problem this is:

```{r}
training %>% 
  gather(variable, value) %>%
  filter(value == 0) %>%
  group_by(variable) %>%
  tally() %>%
  mutate(percent = n / nrow(training) * 100) %>%
  mutate(percent = paste0(round(percent, ifelse(percent < 10, 1, 0)), "%")) %>%
  arrange(desc(n)) %>%
  rename(`Variable With Zeros` = variable,
         `Number of Records` = n,
         `Share of Total` = percent) %>%
  kable() %>%
  kable_styling()
```

The report shows that missing values are nearly low.

#### Missing Values (NaN)

During our first look at the data it was noted that there were variables that are missing data.  Here's a look at what variables are missing data and how big of a problem it is:

```{r}
training %>% 
  gather(variable, value) %>%
  filter(is.na(value)) %>%
  group_by(variable) %>%
  tally() %>%
  mutate(percent = n / nrow(training) * 100) %>%
  mutate(percent = paste0(round(percent, ifelse(percent < 10, 1, 0)), "%")) %>%
  arrange(desc(n)) %>%
  rename(`Variable Missing Data` = variable,
         `Number of Records` = n,
         `Share of Total` = percent) %>%
  kable() %>%
  kable_styling()
```

The "TEAM_BATTING_HBP"" varriable has "NaN" nearly 92%.  We will exclude this variable from consideration in our model.

#### Correlations Matrix

Let's take a look at the correlations.  The following is the correlations from the complete cases only:

```{r correlation plot}
training %>% 
  cor(., use = "complete.obs") %>%
  corrplot(., method = "color", type = "upper", tl.col = "black", diag = FALSE)
```
Anything over 0.5 or under -0.5 is highlighted in blue. The matrix was created using complete pairwise observations.

A few conclusions: 

- Not surprisingly there is a very strong correlation between home runs batted in and home runs given up by pitching.
- There is a negative correlation between number of triples and home runs. A less powerful team may not have enough power to hit home runs, but they get a lot of triples. 
- THere is a strong positive correlation between number of strikeouts and home runs. More swings of the bat results in more home runs. 

#### Correlations: Endogenous and  Exogenous Variables

Let's take a look at how the Exogenous(Model Inputs) are correlated with the response variable(Endogenous):

```{r warning=FALSE}
training %>%
  gather(variable, value, -TARGET_WINS) %>%
  ggplot(., aes(value, TARGET_WINS)) + 
  geom_point(fill = "indianred4", color="grey") + 
  geom_smooth(method = "lm", se = FALSE, color = "black") + 
  facet_wrap(~variable, scales ="free", ncol = 4) +
  labs(x = element_blank(), y = "Wins")
```

### Variable chacteristics
Each variable is presented below with corresponding basic statistics (minimum, median and maximum values, mean and standard deviation, number of records with missing values), boxplot, density plot with highlighted mean value, and scatterplot against outcome variable (`TARGET_WINS`) with best fit line. This information is used to check general validity of data and adjust as necessary. 


#### TEAM_BATTING_H: 

This variable represents number of team base hits:

```{r echo=FALSE, warning=FALSE, message=FALSE, fig.width=10, fig.height=6}
kable(sumtable[sumtable[,1]=="TEAM_BATTING_H",2:7], row.names=FALSE)

# Boxplot
ggplot(training, aes(x = 1, y = TEAM_BATTING_H)) + 
  stat_boxplot(geom ='errorbar') + geom_boxplot() + 
  xlab("Boxplot") + ylab("") + theme(axis.text.x=element_blank(), axis.ticks.x=element_blank())

# Density plot
ggplot(training, aes(x = TEAM_BATTING_H)) + 
  geom_histogram(aes(y=..density..), colour="black", fill="white",bins=50) +
  geom_density(alpha=.2, fill="#FF6666") + ylab("") + xlab("Density Plot with Mean") +
  geom_vline(aes(xintercept=mean(TEAM_BATTING_H, na.rm=TRUE)), color="red", linetype="dashed", size=1)

# Scatterplot
ggplot(data=training, aes(x=TEAM_BATTING_H, y=TARGET_WINS)) + 
  geom_point() + geom_smooth(method = "loess") +
  xlab("Scatterplot with Best Fit Line")
```

**Data Overview:** There are no missing values. The range and distribution are reasonable.


#### TEAM_BATTING_2B:

This variable represents number of team doubles:

```{r echo=FALSE, warning=FALSE, message=FALSE, fig.width=10, fig.height=6}
kable(sumtable[sumtable[,1]=="TEAM_BATTING_2B",2:7], row.names=FALSE)
# Boxplot
ggplot(training, aes(x = 1, y = TEAM_BATTING_2B)) + 
  stat_boxplot(geom ='errorbar') + geom_boxplot() + 
  xlab("Boxplot") + ylab("") + theme(axis.text.x=element_blank(), axis.ticks.x=element_blank())
# Density plot
ggplot(training, aes(x = TEAM_BATTING_2B)) + 
  geom_histogram(aes(y=..density..), colour="black", fill="white",bins=50) +
  geom_density(alpha=.2, fill="#FF6666") + ylab("") + xlab("Density Plot with Mean") +
  geom_vline(aes(xintercept=mean(TEAM_BATTING_2B, na.rm=TRUE)), color="red", linetype="dashed", size=1)
# Scatterplot
ggplot(data=training, aes(x=TEAM_BATTING_2B, y=TARGET_WINS)) + 
  geom_point() + geom_smooth(method = "loess") +
  xlab("Scatterplot with Best Fit Line")

```

**Data Overview:** There are no missing values. The range and distribution are reasonable.


#### TEAM_BATTING_3B: 

This variable represents  number of team triples:

```{r echo=FALSE, warning=FALSE, message=FALSE, fig.width=10, fig.height=6}
kable(sumtable[sumtable[,1]=="TEAM_BATTING_3B",2:7], row.names=FALSE)
# Boxplot
ggplot(training, aes(x = 1, y = TEAM_BATTING_3B)) + 
  stat_boxplot(geom ='errorbar') + geom_boxplot() + 
  xlab("Boxplot") + ylab("") + theme(axis.text.x=element_blank(), axis.ticks.x=element_blank())
# Density plot
ggplot(training, aes(x = TEAM_BATTING_3B)) + 
  geom_histogram(aes(y=..density..), colour="black", fill="white",bins=50) +
  geom_density(alpha=.2, fill="#FF6666") + ylab("") + xlab("Density Plot with Mean") +
  geom_vline(aes(xintercept=mean(TEAM_BATTING_3B, na.rm=TRUE)), color="red", linetype="dashed", size=1)
# Scatterplot
ggplot(data=training, aes(x=TEAM_BATTING_3B, y=TARGET_WINS)) + 
  geom_point() + geom_smooth(method = "loess") +
  xlab("Scatterplot with Best Fit Line")

```

**Data Overview:**The range and distribution are reasonable. There are 2 records with zero values which is unrealistic for a team in a season. One record (index 1347) has 12 variables with missing values, including the outcome variable. This record will be deleted from the data set. Second record (index 1494) has 7 missing variables, but it does have some recorded values in all categories - batting, pitching and fielding. Zero value for `TEAM_BATTING_3B` can be replaced with the median (because the distribution is right-skewed, median value will provide more realistic estimate).


#### TEAM_BATTING_HR: 

This variable represents  number of team triples:

```{r echo=FALSE, warning=FALSE, message=FALSE, fig.width=10, fig.height=6}
kable(sumtable[sumtable[,1]=="TEAM_BATTING_HR",2:7], row.names=FALSE)
# Boxplot
ggplot(training, aes(x = 1, y = TEAM_BATTING_HR)) + 
  stat_boxplot(geom ='errorbar') + geom_boxplot() + 
  xlab("Boxplot") + ylab("") + theme(axis.text.x=element_blank(), axis.ticks.x=element_blank())
# Density plot
ggplot(training, aes(x = TEAM_BATTING_HR)) + 
  geom_histogram(aes(y=..density..), colour="black", fill="white",bins=50) +
  geom_density(alpha=.2, fill="#FF6666") + ylab("") + xlab("Density Plot with Mean") +
  geom_vline(aes(xintercept=mean(TEAM_BATTING_HR, na.rm=TRUE)), color="red", linetype="dashed", size=1)
# Scatterplot
ggplot(data=training, aes(x=TEAM_BATTING_HR, y=TARGET_WINS)) + 
  geom_point() + geom_smooth(method = "loess") +
  xlab("Scatterplot with Best Fit Line")

```

**Analysis:**There are some low values in the data. So zero doesn't seem too unusual here either.


#### TEAM_BATTING_BB: 

This variable represents Number of team walks

```{r echo=FALSE, warning=FALSE, message=FALSE, fig.width=10, fig.height=6}
kable(sumtable[sumtable[,1]=="TEAM_BATTING_BB",2:7], row.names=FALSE)
# Boxplot
ggplot(training, aes(x = 1, y = TEAM_BATTING_BB)) + 
  stat_boxplot(geom ='errorbar') + geom_boxplot() + 
  xlab("Boxplot") + ylab("") + theme(axis.text.x=element_blank(), axis.ticks.x=element_blank())
# Density plot
ggplot(training, aes(x = TEAM_BATTING_BB)) + 
  geom_histogram(aes(y=..density..), colour="black", fill="white",bins=50) +
  geom_density(alpha=.2, fill="#FF6666") + ylab("") + xlab("Density Plot with Mean") +
  geom_vline(aes(xintercept=mean(TEAM_BATTING_BB, na.rm=TRUE)), color="red", linetype="dashed", size=1)
# Scatterplot
ggplot(data=training, aes(x=TEAM_BATTING_BB, y=TARGET_WINS)) + 
  geom_point() + geom_smooth(method = "loess") +
  xlab("Scatterplot with Best Fit Line")
```

#### TEAM_BATTING_HBP: 

This variable represents Number of team batters hit by pitch

```{r echo=FALSE, warning=FALSE, message=FALSE, fig.width=10, fig.height=6}
kable(sumtable[sumtable[,1]=="TEAM_BATTING_HBP",2:7], row.names=FALSE)
# Boxplot
ggplot(training, aes(x = 1, y = TEAM_BATTING_HBP)) + 
  stat_boxplot(geom ='errorbar') + geom_boxplot() + 
  xlab("Boxplot") + ylab("") + theme(axis.text.x=element_blank(), axis.ticks.x=element_blank())
# Density plot
ggplot(training, aes(x = TEAM_BATTING_HBP)) + 
  geom_histogram(aes(y=..density..), colour="black", fill="white",bins=50) +
  geom_density(alpha=.2, fill="#FF6666") + ylab("") + xlab("Density Plot with Mean") +
  geom_vline(aes(xintercept=mean(TEAM_BATTING_HBP, na.rm=TRUE)), color="red", linetype="dashed", size=1)
# Scatterplot
ggplot(data=training, aes(x=TEAM_BATTING_HBP, y=TARGET_WINS)) + 
  geom_point() + geom_smooth(method = "loess") +
  xlab("Scatterplot with Best Fit Line")

```

**Analysis:** There are 2,085 records - 91.6% of data set - that are missing value. Because this variable is missing for majority of records, I wont consider this variable as input for regression model.

#### TEAM_BATTING_SO: 

This variable represents Number of team strikeouts by batters

```{r echo=FALSE, warning=FALSE, message=FALSE, fig.width=10, fig.height=6}
kable(sumtable[sumtable[,1]=="TEAM_BATTING_SO",2:7], row.names=FALSE)
# Boxplot
ggplot(training, aes(x = 1, y = TEAM_BATTING_SO)) + 
  stat_boxplot(geom ='errorbar') + geom_boxplot() + 
  xlab("Boxplot") + ylab("") + theme(axis.text.x=element_blank(), axis.ticks.x=element_blank())
# Density plot
ggplot(training, aes(x = TEAM_BATTING_SO)) + 
  geom_histogram(aes(y=..density..), colour="black", fill="white",bins=50) +
  geom_density(alpha=.2, fill="#FF6666") + ylab("") + xlab("Density Plot with Mean") +
  geom_vline(aes(xintercept=mean(TEAM_BATTING_SO, na.rm=TRUE)), color="red", linetype="dashed", size=1)
# Scatterplot
ggplot(data=training, aes(x=TEAM_BATTING_SO, y=TARGET_WINS)) + 
  geom_point() + geom_smooth(method = "loess") +
  xlab("Scatterplot with Best Fit Line")

```

**Analysis:** There are 122 records with missing or zero value (as wtih other variables a zero value is unrealistic). These values can be imputed. Similarly to homeruns, the distribution is multimodal, which is interesting enough for additional analysis. Another area of concern is a noticeable left tail. It is highly unlikely to have games without any strikeouts, so anything lower than 162 (average of 1 strikeout per game) is definitely suspect.

#### TEAM_BASERUN_SB: 

This variable represents Number of team stolen bases

```{r echo=FALSE, warning=FALSE, message=FALSE, fig.width=10, fig.height=6}
kable(sumtable[sumtable[,1]=="TEAM_BASERUN_SB",2:7], row.names=FALSE)
# Boxplot
ggplot(training, aes(x = 1, y = TEAM_BASERUN_SB)) + 
  stat_boxplot(geom ='errorbar') + geom_boxplot() + 
  xlab("Boxplot") + ylab("") + theme(axis.text.x=element_blank(), axis.ticks.x=element_blank())
# Density plot
ggplot(training, aes(x = TEAM_BASERUN_SB)) + 
  geom_histogram(aes(y=..density..), colour="black", fill="white",bins=50) +
  geom_density(alpha=.2, fill="#FF6666") + ylab("") + xlab("Density Plot with Mean") +
  geom_vline(aes(xintercept=mean(TEAM_BASERUN_SB, na.rm=TRUE)), color="red", linetype="dashed", size=1)
# Scatterplot
ggplot(data=training, aes(x=TEAM_BASERUN_SB, y=TARGET_WINS)) + 
  geom_point() + geom_smooth(method = "loess") +
  xlab("Scatterplot with Best Fit Line")

```

#### TEAM_BASERUN_CS: 

This variable represents Number of team runners caught stealing

```{r echo=FALSE, warning=FALSE, message=FALSE, fig.width=10, fig.height=6}
kable(sumtable[sumtable[,1]=="TEAM_BASERUN_CS",2:7], row.names=FALSE)
# Boxplot
ggplot(training, aes(x = 1, y = TEAM_BASERUN_CS)) + 
  stat_boxplot(geom ='errorbar') + geom_boxplot() + 
  xlab("Boxplot") + ylab("") + theme(axis.text.x=element_blank(), axis.ticks.x=element_blank())
# Density plot
ggplot(training, aes(x = TEAM_BASERUN_CS)) + 
  geom_histogram(aes(y=..density..), colour="black", fill="white",bins=50) +
  geom_density(alpha=.2, fill="#FF6666") + ylab("") + xlab("Density Plot with Mean") +
  geom_vline(aes(xintercept=mean(TEAM_BASERUN_CS, na.rm=TRUE)), color="red", linetype="dashed", size=1)
# Scatterplot
ggplot(data=training, aes(x=TEAM_BASERUN_CS, y=TARGET_WINS)) + 
  geom_point() + geom_smooth(method = "loess") +
  xlab("Scatterplot with Best Fit Line")

```



#### TEAM_FIELDING_E: 

This variable represents  Number of team fielding errors

```{r echo=FALSE, warning=FALSE, message=FALSE, fig.width=10, fig.height=6}
kable(sumtable[sumtable[,1]=="TEAM_FIELDING_E",2:7], row.names=FALSE)
# Boxplot
ggplot(training, aes(x = 1, y = TEAM_FIELDING_E)) + 
  stat_boxplot(geom ='errorbar') + geom_boxplot() + 
  xlab("Boxplot") + ylab("") + theme(axis.text.x=element_blank(), axis.ticks.x=element_blank())
# Density plot
ggplot(training, aes(x = TEAM_FIELDING_E)) + 
  geom_histogram(aes(y=..density..), colour="black", fill="white",bins=50) +
  geom_density(alpha=.2, fill="#FF6666") + ylab("") + xlab("Density Plot with Mean") +
  geom_vline(aes(xintercept=mean(TEAM_FIELDING_E, na.rm=TRUE)), color="red", linetype="dashed", size=1)
# Scatterplot
ggplot(data=training, aes(x=TEAM_FIELDING_E, y=TARGET_WINS)) + 
  geom_point() + geom_smooth(method = "loess") +
  xlab("Scatterplot with Best Fit Line")

```

#### TEAM_FIELDING_DP: 

This variable represents Number of team fielding double plays

```{r echo=FALSE, warning=FALSE, message=FALSE, fig.width=10, fig.height=6}
kable(sumtable[sumtable[,1]=="TEAM_FIELDING_DP",2:7], row.names=FALSE)
# Boxplot
ggplot(training, aes(x = 1, y = TEAM_FIELDING_DP)) + 
  stat_boxplot(geom ='errorbar') + geom_boxplot() + 
  xlab("Boxplot") + ylab("") + theme(axis.text.x=element_blank(), axis.ticks.x=element_blank())
# Density plot
ggplot(training, aes(x = TEAM_FIELDING_DP)) + 
  geom_histogram(aes(y=..density..), colour="black", fill="white",bins=50) +
  geom_density(alpha=.2, fill="#FF6666") + ylab("") + xlab("Density Plot with Mean") +
  geom_vline(aes(xintercept=mean(TEAM_FIELDING_DP, na.rm=TRUE)), color="red", linetype="dashed", size=1)
# Scatterplot
ggplot(data=training, aes(x=TEAM_FIELDING_DP, y=TARGET_WINS)) + 
  geom_point() + geom_smooth(method = "loess") +
  xlab("Scatterplot with Best Fit Line")

```

#### TEAM_PITCHING_BB: 

This variable represents Number of walks given up by pitchers

```{r echo=FALSE, warning=FALSE, message=FALSE, fig.width=10, fig.height=6}
kable(sumtable[sumtable[,1]=="TEAM_PITCHING_BB",2:7], row.names=FALSE)
# Boxplot
ggplot(training, aes(x = 1, y = TEAM_PITCHING_BB)) + 
  stat_boxplot(geom ='errorbar') + geom_boxplot() + 
  xlab("Boxplot") + ylab("") + theme(axis.text.x=element_blank(), axis.ticks.x=element_blank())
# Density plot
ggplot(training, aes(x = TEAM_PITCHING_BB)) + 
  geom_histogram(aes(y=..density..), colour="black", fill="white",bins=50) +
  geom_density(alpha=.2, fill="#FF6666") + ylab("") + xlab("Density Plot with Mean") +
  geom_vline(aes(xintercept=mean(TEAM_PITCHING_BB, na.rm=TRUE)), color="red", linetype="dashed", size=1)
# Scatterplot
ggplot(data=training, aes(x=TEAM_PITCHING_BB, y=TARGET_WINS)) + 
  geom_point() + geom_smooth(method = "loess") +
  xlab("Scatterplot with Best Fit Line")

```

**Analysis:** There are no missing values with the exception of record 1347 which will be deleted from model building. There are some unrealistic outliers.


#### TEAM_PITCHING_H: 

This variable represents Number of base hits given up by pitchers

```{r echo=FALSE, warning=FALSE, message=FALSE, fig.width=10, fig.height=6}
kable(sumtable[sumtable[,1]=="TEAM_PITCHING_H",2:7], row.names=FALSE)
# Boxplot
ggplot(training, aes(x = 1, y = TEAM_PITCHING_H)) + 
  stat_boxplot(geom ='errorbar') + geom_boxplot() + 
  xlab("Boxplot") + ylab("") + theme(axis.text.x=element_blank(), axis.ticks.x=element_blank())
# Density plot
ggplot(training, aes(x = TEAM_PITCHING_H)) + 
  geom_histogram(aes(y=..density..), colour="black", fill="white",bins=50) +
  geom_density(alpha=.2, fill="#FF6666") + ylab("") + xlab("Density Plot with Mean") +
  geom_vline(aes(xintercept=mean(TEAM_PITCHING_H, na.rm=TRUE)), color="red", linetype="dashed", size=1)
# Scatterplot
ggplot(data=training, aes(x=TEAM_PITCHING_H, y=TARGET_WINS)) + 
  geom_point() + geom_smooth(method = "loess") +
  xlab("Scatterplot with Best Fit Line")

```

**Analysis:** Similar to `TEAM_PITCHING_BB` above, there are no missing value, but there issues with outliers. Based on visualizations, this variable will be capped at 13,000 and any value over this will be set to this cap.

#### TEAM_PITCHING_SO:

This variable represents Number of strikeouts by pitchers

```{r echo=FALSE, warning=FALSE, message=FALSE, fig.width=10, fig.height=6}
kable(sumtable[sumtable[,1]=="TEAM_PITCHING_SO",2:7], row.names=FALSE)
# Boxplot
ggplot(training, aes(x = 1, y = TEAM_PITCHING_SO)) + 
  stat_boxplot(geom ='errorbar') + geom_boxplot() + 
  xlab("Boxplot") + ylab("") + theme(axis.text.x=element_blank(), axis.ticks.x=element_blank())
# Density plot
ggplot(training, aes(x = TEAM_PITCHING_SO)) + 
  geom_histogram(aes(y=..density..), colour="black", fill="white",bins=50) +
  geom_density(alpha=.2, fill="#FF6666") + ylab("") + xlab("Density Plot with Mean") +
  geom_vline(aes(xintercept=mean(TEAM_PITCHING_SO, na.rm=TRUE)), color="red", linetype="dashed", size=1)
# Scatterplot
ggplot(data=training, aes(x=TEAM_PITCHING_SO, y=TARGET_WINS)) + 
  geom_point() + geom_smooth(method = "loess") +
  xlab("Scatterplot with Best Fit Line")

```

**Analysis:** This variable has 122 missing or zero values. They can be imputed as needed. There is also an outlier issue as graph shows.

#### TARGET_WINS: 

This variable represents Number of wins **(Outcome)**

```{r echo=FALSE, warning=FALSE, message=FALSE, fig.width=10, fig.height=6}
kable(sumtable[sumtable[,1]=="TARGET_WINS",2:7], row.names=FALSE)
# Boxplot
ggplot(training, aes(x = 1, y = TARGET_WINS)) + 
  stat_boxplot(geom ='errorbar') + geom_boxplot() + 
  xlab("Boxplot") + ylab("") + theme(axis.text.x=element_blank(), axis.ticks.x=element_blank())
# Density plot
ggplot(training, aes(x = TARGET_WINS)) + 
  geom_histogram(aes(y=..density..), colour="black", fill="white",bins=50) +
  geom_density(alpha=.2, fill="#FF6666") + ylab("") + xlab("Density Plot with Mean") +
  geom_vline(aes(xintercept=mean(TARGET_WINS, na.rm=TRUE)), color="red", linetype="dashed", size=1)

```
**Analysis:** The range and distribution are reasonable. There are no missing values with the exception of record 1347.

## DATA PREPARATION

### Fixing Missing/Zero Values

First we will remove the invalid data and prep it for imputation.  We will drop the hit by pitcher variable from the dataset.

```{r}
clean_data <- function(df){
  # Change 0's to NA so they too can be imputed
  df <- df %>%
  mutate(TEAM_BATTING_SO = ifelse(TEAM_BATTING_SO == 0, NA, TEAM_BATTING_SO))
  # Remove the high pitching strikeout values
  df[which(df$TEAM_PITCHING_SO > 5346),"TEAM_PITCHING_SO"] <- NA
  # Drop the hit by pitcher variable
  df %>%
    select(-TEAM_BATTING_HBP)
}
training <- clean_data(training)
evaluation <- clean_data(evaluation)
```

### KNN imputation 

```{r}
set.seed(42)
knn <- training %>% knnImputation()
apply_func <- function(df, knn){
  impute_me <- is.na(df$TEAM_BATTING_SO)
  df[impute_me,"TEAM_BATTING_SO"] <- knn[impute_me,"TEAM_BATTING_SO"] 
  impute_me <- is.na(df$TEAM_BASERUN_SB)
  df[impute_me,"TEAM_BASERUN_SB"] <- knn[impute_me,"TEAM_BASERUN_SB"] 
  impute_me <- is.na(df$TEAM_BASERUN_CS)
  df[impute_me,"TEAM_BASERUN_CS"] <- knn[impute_me,"TEAM_BASERUN_CS"] 
  impute_me <- is.na(df$TEAM_PITCHING_SO)
  df[impute_me,"TEAM_PITCHING_SO"] <- knn[impute_me,"TEAM_PITCHING_SO"]
  impute_me <- is.na(df$TEAM_FIELDING_DP)
  df[impute_me,"TEAM_FIELDING_DP"] <- knn[impute_me,"TEAM_FIELDING_DP"]
  return(df)
}
training <- apply_func(training, knn)
```
### Feature Engineering

The batting singles is not included but we can back it out of the hits.  We will do this.

```{r}
add_features <- function(df){
  df %>%
    mutate(TEAM_BATTING_1B = TEAM_BATTING_H - TEAM_BATTING_2B - TEAM_BATTING_3B - TEAM_BATTING_HR)
}
training <- add_features(training)
evaluation <- add_features(evaluation)
```
### Model Data Look

Here's what the data look like after imputation and correction:

```{r warning=FALSE}
training %>%
  gather(variable, value) %>%
  ggplot(., aes(value)) + 
  geom_density(fill = "indianred4", color="indianred4") + 
  facet_wrap(~variable, scales ="free", ncol = 4) +
  labs(x = element_blank(), y = element_blank())
```

```{r}
quick_summary <- function(df){
  df %>%
    summary() %>%
    kable() %>%
    kable_styling()
}
quick_summary(training)
```

## BUILD MODELS

### Model 1

The first model includes several variables, selected manually, that have higher than average correlation to the target variable. They cover hitting, walking and fielding errors.

```{r echo=FALSE, warning=FALSE, message=FALSE}
m1 <- lm(TARGET_WINS ~ TEAM_BATTING_H + TEAM_BATTING_BB + TEAM_FIELDING_E, data=training)
summary(m1)
```

All variables are significant, but the $R^2$ value is relatively small at 0.2356.

### Model 2

The second model expand the base hit variable, `TEAM_BATTING_H`, into its components - singles, doubles, triples and home runs. 

```{r echo=FALSE, warning=FALSE, message=FALSE}
m2 <- lm(TARGET_WINS ~ TEAM_BATTING_1B + TEAM_BATTING_2B + TEAM_BATTING_3B + TEAM_BATTING_HR + 
           TEAM_BATTING_BB + TEAM_FIELDING_E, data=training)
summary(m2)
```

All variables are still significant and $R^2$ is slightly improved at 0.2574.


### Higher Order Stepwise Regression

For the third model we will use a stepwise regression method using a backwards elimination process.  We also introduce some higher order polynomial variables.

```{r}
full_formula <- "TARGET_WINS ~ TEAM_BATTING_2B + TEAM_BATTING_3B + TEAM_BATTING_HR + TEAM_BATTING_BB + TEAM_BATTING_SO + TEAM_BASERUN_SB + TEAM_BASERUN_CS + TEAM_PITCHING_H + TEAM_PITCHING_HR + TEAM_PITCHING_BB + TEAM_PITCHING_SO + TEAM_FIELDING_E + TEAM_FIELDING_DP + TEAM_BATTING_1B + I(TEAM_BATTING_2B^2) + I(TEAM_BATTING_3B^2) + I(TEAM_BATTING_HR^2) + I(TEAM_BATTING_BB^2) + I(TEAM_BATTING_SO^2) + I(TEAM_BASERUN_SB^2) + I(TEAM_BASERUN_CS^2) + I(TEAM_PITCHING_H^2) + I(TEAM_PITCHING_HR^2) + I(TEAM_PITCHING_BB^2) + I(TEAM_PITCHING_SO^2) + I(TEAM_FIELDING_E^2) + I(TEAM_FIELDING_DP^2) + I(TEAM_BATTING_1B^2) "
full_model <- lm(full_formula, training)
step_back <- MASS::stepAIC(full_model, direction="backward", trace = F)
poly_call <- summary(step_back)$call
step_back <- lm(poly_call[2], training)
summary(step_back)
```
This model has the highest adjusted R-squared value .Some variables p-values are not in 95 % siginificant level but they are in 90 % significant level which is acceptable.

## SELECT MODELS

In order to select which model is the "best" we will test it against a validation(evaluation) set.  We will examine the difference between the predicted and actual values.
